{
"cells": [
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"# Initialize Otter\n",
"import otter\n",
"grader = otter.Notebook(\"HW_1_data_numpy.ipynb\")"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"# HW 1: Statistical analysis of data using numpy and matplotlib\n",
"\n",
"Resources: Lecture slides describing the homework: https://docs.google.com/presentation/d/1ef0msC9XIT37_Yg94Cf4TL9VBgbIIfkKik8jgshskjE/edit?usp=sharing\n",
"\n",
"Please do lab 1 before starting this homework, and do lab 2 before tackling problem 4 (the plotting part).\n",
"\n",
"In this homework the focus is on code *design*. Most of the functionality of the code will be what you did in the labs. I don't expect you to do the code design; I've provided that. Just pay attention to how a couple of code structuring tools (functions, dictionaries) can make your code a little more re-usable, cleaner, and less prone to error. \n",
"\n",
"- Generalization 1: Put the code that calculates the statistics into a function \n",
"- Generalization 2: Store the results in a dictionary so it's labeled and you don't have to worry about variable name re-use\n",
"\n",
"Learning to *read* code is also as important as *writing* code. This is (hopefully) a gentle introduction to using/interacting with more advanced concepts/syntax/semantics. \n",
"\n",
"Where you're going with Problems 1, 2, and 3: Take a look in the **Data** directory at the **week_1_check_results.json** file (open it up with a text editor). Compare it to **proxy_data_description.json**.  When you are done with problems 1-3 you will have a dictionary that has the statistical summary data in it."
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Week 1, problem 0: Setting up libraries\n",
"TODO: Import the libraries that you will need (numpy, json, matplotlib for week 2)"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# Libraries that we need to import - numpy and json (for loading the description file)\n",
"\n",
"\n",
"# TODO: put the numpy, json, and matplotlib (week 2) imports here so you can use those libraries (see the tops of Lab 1 & 2)"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"imports\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Week 1, problem 1: stats for one channel function\n",
"\n",
"The idea behind this function is to encapsulate getting all of the statistics for a single channel of data in **proxy_pick_data.csv**. Conceptually, this function does the same thing as all the code up through \"compute stats\" in lab1 - but for *any* channel, not just the wrist torque channel. And we'll throw in some additional stats to compute (mean and standard deviation). In summary:\n",
"\n",
"- Figure out where to start slicing (index_wrist_torque_offset in lab 1)\n",
"- Figure out the spacing to use for slicing (n_total_dims)\n",
"- Actually slice the data\n",
"- Compute the stats for that slice of data\n",
"\n",
"Because it's a function, we need to pass in all of the data/information we're going to need to compute the slice. There are many possible solutions to this, the one I chose was:\n",
"\n",
"- Pass in the original data as the first parameter (this will be pick_data, minus the last column with the successful/unsuccessful information)\n",
"- The channel information from the dictionary (this has the channel name, the start index, and the number of dimensions)\n",
"- Which dimension of the data (x, y, or z)\n",
"- What spacing to use (n_total_dims)\n",
"\n",
"The last parameter isn't strictly necessary - we could recompute it within this function - but since we have it, and it's the same for all channels, compute it once and pass it in.\n",
"\n",
"Note that, instead of passing in which dimension we are interested in, this function *could* have computed all three dimensions and returned the stats for all three. No real reason to do it one way or the other (and, in fact, if you want to try doing it that way, go ahead)."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"def get_stats_for_channel(data, channel_info, xyz_dim, n_total_dims):\n",
"    \"\"\" Get the min, max, mean, standard deviation stats for the given channel and dimension\n",
"    @param data - the numpy array from the csv file (pick_data)\n",
"    @param channel_info - a dictionary with the channel info, which has in it the name, index_offset, and dimensions\n",
"      This is the data channel information in proxy_pick_description\n",
"    @param xyz_dim - 0, 1, or 2 for x, y, z\n",
"    @param n_total_dims - total number of columns per one time step\n",
"    @returns - A dictionary with the statistics values \"\"\"\n",
"\n",
"    # TODO: Calcluate min, max, mean, and standard deviation for the data channel - first part of lab 1\n",
"    \n",
"    # Printing these here so you can see what they are - take them out when the function is working\n",
"    print(f\"Data size: {data.shape}\")\n",
"    print(f\"Channel info: {channel_info}\")\n",
"    print(f\"xyz_dim: {xyz_dim}\")\n",
"    print(f\"n total dims: {n_total_dims}\")\n",
"    # This is found in the channel_info dictionary, with the key \"index_offset\"    \n",
"    index_offset = ... \n",
"    \n",
"    # The np.min(data[:, start:end:stop]) code from lab replaces the 0 \n",
"    ret_stats = {\"Min\": 0,\n",
"                 \"Max\": 0,\n",
"                 \"Mean\": 0,\n",
"                 \"SD\": 0}\n",
"    return ret_stats\n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# Test data - 5 rows with duplicate data, 2 channels \n",
"#.  first channel is t values between 0 and 2 pi\n",
"#   second column is cos(t)\n",
"# Note that passing this test does not mean that EVERYTHING is correct with your function - but it should catch most\n",
"# of the errors\n",
"n_rows = 5\n",
"n_channels = 2\n",
"n_time_steps = 360\n",
"data = np.zeros((n_rows, n_channels * n_time_steps))\n",
"for i in range (0, n_rows):\n",
"    data[i, 0::n_channels] = np.linspace(0, 2 * np.pi, n_time_steps)\n",
"    data[i, 1::n_channels] = np.cos(np.linspace(0, 2 * np.pi, n_time_steps))\n",
"\n",
"channel_info_cos = {\"name\": \"cos\",\n",
"                    \"index_offset\": 1,\n",
"                    \"units\": \"inches\"}\n",
"\n",
"# Actually call the function\n",
"# Before you edit the function above this will print out the input parameters \n",
"ret_stats = get_stats_for_channel(data=data, channel_info=channel_info_cos, xyz_dim=0, n_total_dims=n_channels)\n",
"\n",
"# ... and return 0's for all values\n",
"print(ret_stats)\n",
"\n",
"# When the function is working correctly ret_stats will be (don't forget to take out the print statements in the function)\n",
"#   You should verity for yourself that these values are correct for data that goes form cos(0) to cos(2pi)...\n",
"# {'Min': -0.9999617106423081, 'Max': 1.0, 'Mean': 0.0027777777777776512, 'SD': 0.7080827443452539}"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"stats_function\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Week 1, problem 2: Read in the proxy pick data and the proxy pick description file\n",
"\n",
"Read in both the data file (**proxy_pick_data.csv**) and the file that describes the data (**proxy_data_description.json**). See Lab 1."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"# TODO: Copy code from lab 1 to read in proxy_pick_data.csv and put it in pick_data\n",
"pick_data = ...\n",
"# TODO Copy code to read in proxy_data_description.json and put it in pick_data_description\n",
"pick_data_description = ..."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"read_data\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Week 1: Problem 3: calculate and store data\n",
"\n",
"Calculate **n_total_dims** and **n_time_steps** as in lab 1, but this time store them as items in the **pick_data_description** dictionary.\n",
"\n",
"Why: Two reasons. First, that information, conceptually, belongs there. As we'll see in later homeworks, having all related data in a dictionary means you just have to pass around the dictionary, not all of the individual variables. Second, it's always a good idea to minimize the number of loose variables floating around.\n",
"\n",
"Drawbacks: There's a tiny overhead for accessing values from a dictionary (eg, d[\"foo\"]) and you have to remember what key you used when you put the data in."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# TODO: Calculate the total dimensions and time steps and store them in the dictionary, using the given keys\n",
"#  You MUST calculate these - not just set them to be 33, and 40 (which are the correct answers)\n",
"pick_data_description[\"n_total_dims\"] = ...\n",
"pick_data_description[\"n_time_steps\"] = ..."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"calculate\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"##  Week 1: Problem 4: Print stats for each sensor channel\n",
"\n",
"At this point it's time to do the actual work - calculating the stats for each sensor channel, and storing them back in the **pick_data_description variable**. \n",
"\n",
"I've set this up so that you can write the function **get_stats_for_channel** (already done), then check it (step 1), then incrementally add in the **for** loops (steps 2 and 3). You're free to jump straight to step 3 if you want, but if it doesn't work, please go through steps 1 and 2 before asking the TA for help."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# The pick_data[:,:-1] (instead of pick_data) excludes the last column from the calculation\n",
"# Call the get stats with the first data channel, x dimension, and your pre-calculated total number of dimensions\n",
"ret_stats = get_stats_for_channel(pick_data[:,:-1], pick_data_description[\"Data channels\"][0], 0, pick_data_description[\"n_total_dims\"])\n",
"print(ret_stats)"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"# TODO: Turn the following pseudo code into real code\n",
"#. for each item in data channels\n",
"#.    Print the channel name\n",
"#.    Get the stats:\n",
"#        m_stats = get_stats_for_channel([fill in correct parameters - set xyz_dim to 0])\n",
"#     print(f\"  minimum: {my_stats['Min']}, maximum: {my_stats['Max']}, mean: {my_stats['Mean']}, SD: {my_stats['SD']}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# Cute trick to map 0-2 to letters\n",
"map_to_xyz = ['x', 'y', 'z']\n",
"\n",
"#. TODO: turn this pseudo code into real code\n",
"# for each item in data channels\n",
"#.    Print the channel name\n",
"#.    Create an empty list d[\"stats\"] = [] \n",
"#.    for each dimension in channel\n",
"#.       Get the stats m_stats = get_...\n",
"#.       ... and store them in d[\"stats\"]\n",
"#        print(f\"  minimum: {my_stats['Min']}, maximum: {my_stats['Max']}, mean: {my_stats['Mean']}, SD: {my_stats['SD']}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"with open('Data/week1_student_results.json', 'w') as f:\n",
"    json.dump(pick_data_description, f, indent=4)"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# Putting this here so you can use it to check your answers\n",
"def compare_files():\n",
"    with open(\"Data/week1_student_results.json\", \"r\") as fp:\n",
"        student = json.load(fp)\n",
"    with open(\"Data/week1_check_results.json\", \"r\") as fp:\n",
"        check = json.load(fp)\n",
"\n",
"    for k, v in check.items():\n",
"        try:\n",
"            if k == \"Data channels\":\n",
"                # The data channels list\n",
"                for i, d in enumerate(student[k]):\n",
"                    if not d == v[i]:\n",
"                        print(f\"miss-match {d} {v[i]}\")\n",
"                        return False\n",
"            else:\n",
"                if not v == student[k]:\n",
"                    print(f\"Miss-match key-item {k} {v} {student[k]}\")\n",
"                    return False\n",
"        except KeyError:\n",
"            print(f\"Missing key {k}\")\n",
"            return False\n",
"    return True"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"if compare_files():\n",
"    print(\"Files are the same!\")\n",
"else:\n",
"    print(\"Files are NOT the same, test failed\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"stats_for_all_channels\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Week 1: Problem 5: Max peak per channel\n",
"\n",
"Find the row(s) with the maximum peak in the Wrist torque Z channel\n",
"\n",
"This is the optional problem from lab 1.\n",
"\n",
"Notes for this problem\n",
" - No **for loops** - do this with **np.where**.\n",
" - We should be able to change channel_to_search to a different text string and it still works.\n",
" - i.e., no \"hard-wiring\" the channel name/index\n",
"\n",
"Optional: Do this for all channels and dimensions\n",
"\n",
"Recommended order of implementation for the optional version (see lab 1 for the non-optional version):\n",
" - Write the code for one channel, make sure it works\n",
" - Create a function just like **get_stats_for_channel** above (it will take the same input parameters)\n",
" --    The return value will be different - I suggest a list of tuples with [(r, c), (r, c)]\n",
" -  Copy your code for one channel into the function, and change it to take in the function's input parameters\n",
" - For the output, I suggest making an empty list, and then, in the **for** loop, append all valid **r,c** pairs onto the list. Return the list.\n",
" - Copy your **for** loop from the previous pribken (that goes over all channels, all dimensions) and replace the function call **get_stats_for_channel** with the new one."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"# This should be of the form (r,c). For the wrist torque channel, the answer is (82, 863)\n",
"row_max_wrist_torque_z = ..."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"channel_index\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"<!-- BEGIN QUESTION -->\n",
"\n",
"## Week 2: Problem 1a: Plot wrist force/torque for two rows\n",
"\n",
"Plot the wrist force/torque data for the first and second row. The plots should have in them:\n",
" - Left-hand-side: The wrist force (x,y,z), with horizontal lines for the minimum and maximum z force values\n",
" - Title should include which pick/row this is, and if it is successful or not\n",
" - Right-hand-side: The wrist torque (x,y,z), with horizontal lines for the minimum and maximum z force values\n",
" - Title should include which pick/row this is, and if it is successful or not\n",
" \n",
" - Top row: row 0\n",
" - Bottom row: row 1\n",
" - See https://docs.google.com/presentation/d/1ef0msC9XIT37_Yg94Cf4TL9VBgbIIfkKik8jgshskjE/edit?usp=sharing for what this should look like\n"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"I'm going to give you a function definition for the plot. There are a lot of ways you could do this; I chose this one for two reasons:\n",
"- It \"makes sense\" that the input should be x and y values, along with information on how to label the plot\n",
"- It's a look-ahead to problem 2, where we will re-factor the data into something a little more manageable\n",
"\n",
"Some observations\n",
"-  This pushes the data slicing out of this function and into the calling one\n",
"-  Your choice on how you pass the last parameter\n",
"-  The function parameters also act as \"documentation\" for the data slicing/extracting the pick channel\n",
"\n",
"For this problem you can assume that the y values are 3xn (x, y, z)\n",
"-  Optional: handle the case when it's just 1 dimensional data\n",
"\n",
"To create the horizontal lines, do a plot with (t0, tlast), (max, max) OR use axhline\n",
"Don't forget to import matplotlib"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"def plot_channel_row(axs, ts, ys, channel_info, which_row, pick_successful_yn):\n",
"    \"\"\" Plot a specific channel, all dimensions\n",
"    @param axs - the axes of the plot to use\n",
"    @param ts - t values of the data [1 x n time steps]\n",
"    @param ys - y values of the data [3 x n time steps] OR [1 x n time steps] (supporting the OR is optional)\n",
"    @param channel_info - the channel info from your week1_student_results.json file (which has the min and max)\n",
"    @param which_row - which row this is\n",
"    @param pick_successful_yn - was this a successful pick, y/n?\"\"\"\n",
"\n",
"\n",
"    # TODO: Copy your lab 2 part 2 code here\n",
"    #. Plot t vs ys for the three rows of the ys matrix\n",
"    #  Add an x axis label\n",
"    #  Add a y axis label (using the units in the channel_info)\n",
"    #. Add a title (using the name in the channel_info)\n",
"    #  Add a legend\n",
"    #  Add horizontal lines for the min/max values (which should be stored in the channel_info now)\n",
"    # Example plot command\n",
"    axs.plot(ts, ys[0], label=\"x\")\n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"n_rows = 2\n",
"n_cols = 2\n",
"fig, axs = plt.subplots(n_rows, n_cols)\n",
"\n",
"# Extract data and call plot_channel_row"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"<!-- END QUESTION -->\n",
"\n",
"## Week, 2: Problem 1b: Plot Wrist force/torque for min/max wrist torque z\n",
"\n",
"Find the row that has the maximum (minimum) wrist torque z value. Plot the minimum one in the top row, the maximum\n",
"one in the bottom row\n",
"\n",
"Your actual plotting code (the function) shouldn't have to change, btw. Just what data you send it.\n",
"\n",
"Starting point: the function you wrote in the first week, get_row_with_max_peak"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"..."
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Week 2: Problem 2: (optional) use reshape to make slicing not needed\n",
"\n",
"np.reshape is the method you want; rearrange the data into rows, data channels, time series in each data channel (a 3 dimensional array)"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"n_rows = 2\n",
"n_cols = 2\n",
"fig, axs = plt.subplots(n_rows, n_cols)\n",
"\n",
"# Re-organize the data into an n_picks * n_channel_dims * n_time_steps (3 dimensional) array\n",
"pick_data_reorg = ...   # Use reshape, with the correct \"order\" option\n",
"# ... and another array that stores just the success/fail data\n",
"pick_data_success_fail = ...\n",
"\n",
"# Then this plot call should plot the wrist force data for row zero\n",
"row = 0\n",
"plot_channel_row(axs[0, 0], ts, pick_data_reorg[row, 0:3, :], data_channels[0], which_row=row, pick_data_success_fail[row] == 1)\n",
"\n",
"# ... and for wrist torque data\n",
"plot_channel_row(axs[0, 1], ts, pick_data_reorg[row, 3:6, :], data_channels[1], which_row=row, pick_data_success_fail[row] == 1)\n",
"\n"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Hours and collaborators\n",
"Required for every assignment - fill out before you hand-in.\n",
"\n",
"Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
"\n",
"Listing hours helps us track if the assignments are too long."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"# List of names (creates a set)\n",
"worked_with_names = {\"not filled out\"}\n",
"# List of URLS (creates a set)\n",
"websites = {\"not filled out\"}\n",
"# Approximate number of hours, including lab/in-class time\n",
"hours = -1.5\n",
"\n",
"# for all row, column in all_indices_from_where\n",
"#.   if this is the column for wrist torque \n",
"#.      print(f\"Row: {r}, Time step: {c // n_time_steps} Successful y/n: {pick_data[r, -1] == 1}, value: {pick_data[r, c]}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"hours_collaborators\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Submission\n",
"\n",
"Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
"\n",
"Submit just the .ipynb file to Gradescope, HWK1 Arrays and Plotting. You do not need to put in the data files. Don't change the provided variable names or autograding will fail."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"# Save your notebook first, then run this cell to export your submission.\n",
"grader.export(run_tests=True)"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
" "
]
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.7.4"
},
"otter": {
"OK_FORMAT": true,
"tests": {
"calculate": {
"name": "calculate",
"points": 2,
"suites": [
{
"cases": [
{
"code": ">>> assert(pick_data_description[\"n_total_dims\"] == 33)\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert(pick_data_description[\"n_time_steps\"] == 40)\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"channel_index": {
"name": "channel_index",
"points": 2,
"suites": [
{
"cases": [
{
"code": ">>> assert(row_max_wrist_torque_z[0:2] == (82, 863))\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"hours_collaborators": {
"name": "hours_collaborators",
"points": 1,
"suites": [
{
"cases": [
{
"code": ">>> assert(not \"not filled out\" in worked_with_names)\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert(not \"not filled out\" in websites)\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert(hours > 0)\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"imports": {
"name": "imports",
"points": 1,
"suites": [
{
"cases": [
{
"code": ">>> assert(np.isclose(np.min(np.zeros(3)), 0.0))\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"read_data": {
"name": "read_data",
"points": 3,
"suites": [
{
"cases": [
{
"code": ">>> assert(pick_data.shape == (660, 1321))\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert(pick_data_description[\"Pick data file\"] == \"proxy_pick_data.csv\")\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"stats_for_all_channels": {
"name": "stats_for_all_channels",
"points": 3,
"suites": [
{
"cases": [
{
"code": ">>> assert(compare_files())\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"stats_function": {
"name": "stats_function",
"points": 5,
"suites": [
{
"cases": [
{
"code": ">>> assert(np.isclose(ret_stats['Min'], -1.0, 0.001))\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert(np.isclose(ret_stats['Max'], 1.0, 0.001))\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert(np.isclose(ret_stats['Mean'], 0.0027777, 0.01))\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert(np.isclose(ret_stats['SD'],0.70808274, 0.01))\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
}
}
}
},
"nbformat": 4,
"nbformat_minor": 2
}