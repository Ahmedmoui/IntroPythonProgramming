{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW_1_data_numpy.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1: Statistical analysis of data using numpy and matplotlib\n",
    "\n",
    "Resources: Lecture slides describing the homework: https://docs.google.com/presentation/d/1ef0msC9XIT37_Yg94Cf4TL9VBgbIIfkKik8jgshskjE/edit?usp=sharing\n",
    "\n",
    "Please do lab 1 before starting this homework, and do lab 2 before tackling problem 4 on (the plotting part).\n",
    "\n",
    "In this homework the focus is on code *design*. Most of the functionality of the code will be what you did in the labs. I don't expect you to do the code design; I've provided that. Just pay attention to how a couple of tools (functions, dictionaries) can make your code a little more re-usable, cleaner, and less prone to error. \n",
    "\n",
    "Learning to *read* code is also as important as *writing* code. This is (hopefully) a gentle introduction to using/interacting with more advanced concepts/syntax/semantics. \n",
    "\n",
    "Where you're going with Problems 1, 2, and 3: Take a look in the **Data** directory at the **week_1_check_results.json** file. This is what your code should produce after those problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up libraries and reading in data\n",
    "Import the libraries that you will need (numpy, json, matplotlib for week 2) and read in the data you will need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries that we need to import - numpy and json (for loading the description file)\n",
    "\n",
    "# Need this for autograding to work\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "\n",
    "# TODO: put the numpy and json imports here so you can use those libraries (see the top of Lab 1 & 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pick_data = ...\n",
    "# Code to read in pick_data_description\n",
    "pick_data_description = ...\n",
    "# Code to get data_channels out of pick_data_description\n",
    "data_channels = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pick_data_description[\"n_total_dims\"] = ...\n",
    "pick_data_description[\"n_time_steps\"] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"initialize_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Print stats for each sensor channel\n",
    "\n",
    "This is almost entirely copying your code from lab 1 into a new structure that makes it easier to generalize your code. I've provided the structure, and broken the process up into 3 steps.\n",
    "\n",
    "- Generalization 1: Put the code that calculates the statistics into a function\n",
    "- Generalization 2: Store the results in a dictionary so it's labeled and you don't have to worry about variable name re-use\n",
    "\n",
    "Note: You should not use **pick_data** and **pick_data_description** *inside* your function. They are passed in as variables to the function.\n",
    "\n",
    "I've set this up so that you can write the function, then check it, then incrementally add in the **for** loops. You're free to jump straight to step 3 if you want, but if it doesn't work, please go through steps 1 and 2 before asking the TA for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stats_for_channel(data, channel_info, xyz_dim, n_total_dims):\n",
    "    \"\"\" Get the min, max, mean, sd for the given channel\n",
    "    @param data - the numpy array from the csv file (pick_data)\n",
    "    @param channel_info - a dictionary with the channel info, which has in it the name, index_offset, and dimensions\n",
    "    @param xyz_dim - 0, 1, or 2 for x, y, z\n",
    "    @param n_total_dims - total number of columns per one time step\n",
    "    @returns - A dictionary with the statistics values \"\"\"\n",
    "\n",
    "    # This is index_wrist_torque_offset from lab 1 - the start index from the dictionary plus the dimension (xyz_dim)\n",
    "    # Do the same thing you did in lab 1 (get the index_offset from channel_info) then add in the x,y,z offset\n",
    "    index_offset = ... \n",
    "    \n",
    "    # The np.min(data[:, start:end:stop]) code from lab replaces the 0 \n",
    "    ret_stats = {\"Min\": 0,\n",
    "                 \"Max\": 0,\n",
    "                 \"Mean\": 0,\n",
    "                 \"SD\": 0}\n",
    "    return ret_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ret_stats = get_stats_for_channel(pick_data, data_channels[0], 0, pick_data_description[\"n_total_dims\"])\n",
    "print(ret_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#. for each item in data channels\n",
    "#.    Print the channel name\n",
    "#.    Get the stats m_stats = get_...\n",
    "#     print(f\"  minimum: {my_stats['Min']}, maximum: {my_stats['Max']}, mean: {my_stats['Mean']}, SD: {my_stats['SD']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cute trick to map 0-2 to letters\n",
    "map_to_xyz = ['x', 'y', 'z']\n",
    "\n",
    "#. for each item in data channels\n",
    "#.    Print the channel name\n",
    "#.    Create an empty list d[\"stats\"] = [] \n",
    "#.    for each dimension in channel\n",
    "#.       Get the stats m_stats = get_...\n",
    "#.       ... and store them in d[\"stats\"]\n",
    "#        print(f\"  minimum: {my_stats['Min']}, maximum: {my_stats['Max']}, mean: {my_stats['Mean']}, SD: {my_stats['SD']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write the results back out to a text file you can read in a text editor\n",
    "with open('Data/week1_student_results.json', 'w') as f:\n",
    "    json.dump(pick_data_description, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"calc_stats_in_function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max peak per channel\n",
    "\n",
    "Find the row(s) with the maximum peak in the Wrist torque Z channel\n",
    "\n",
    "This is the optional problem from lab 1.\n",
    "\n",
    "Notes for problem 3\n",
    " - No for loops - do this with np.where.\n",
    " - We should be able to change channel_to_search to a different text string and it still works.\n",
    " - i.e., no \"hard-wiring\" the channel name/index\n",
    "\n",
    "Optional: Do this for all channels and dimensions\n",
    "\n",
    "Recommended order of implementation for the optional version (see lab 1 for the non-optional version):\n",
    " - Write the code for one channel, make sure it works\n",
    " - Create a function just like the one above (it will take the same input parameters)\n",
    " --    The return value will be different - I suggest a list of tuples with [(r, c), (r, c)]\n",
    " -  Copy your code for one channel into the function, and change it to take in the function's input parameters\n",
    " - For the output, I suggest making an empty list, and then, in the for loop, append all valid r,c pairs onto the list. Return the list.\n",
    " - Copy your for loop from above (that goes over all channels, all dimensions) and replace the function call with the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# This should be of the form (r,c)\n",
    "row_max_wrist_torque_z = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"channel_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use slicing to get out all of the wrist Force data and calculate the min and the max\n",
    "\n",
    "This is a pretty complicated slice. Steps to get there:\n",
    "-First, use the slice operator, selecting all rows and columns, **data[:, :]** to calculate the minimum across the entire matrix of data. This should be the same as **np.min(pick_data)**\n",
    "- Now change the column slice from all columns to starting at the offset value.\n",
    "- Now change the slice to take a step/stride of **n_total_dims** instead of 1\n",
    "- Reminder: slicing is  **start:end:step**\n",
    "\n",
    "Note: You don't need to put an end value in - just leave it blank\n",
    "\n",
    "Remember: The data is in **pick_data**, not **pick_data_description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "min_wrist_force = ...\n",
    "max_wrist_force = ...\n",
    "print(f\"Minimum {min_wrist_force} and maximum {max_wrist_force} value of wrist force z channel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean slicing to get successful versus unsuccessful picks out\n",
    "\n",
    "Now for the fun one - do the same but ONLY for successful (last column is 1) picks versus unsuccessful (last column is 0)\n",
    "\n",
    "Note: Use == 1, not **is** 1\n",
    "\n",
    "It may be helpful here to explicitly create a boolean array that is # rows X 1 to use as the row index for the\n",
    "pick_data, rather than trying to do it \"in-place\". Then you can check that the array is correct (print it out - it should have Trues and Falses in the same order as the 1s and 0s in the spreadsheet's last column).\n",
    "\n",
    "This boolean array replaces the **:** row index: **data[boolean_array, start:end:step]**\n",
    "\n",
    "The boolean array is created by doing a comparison, for example, **data == 1**. In this case, you want to get out all rows, but only the LAST column of the data, and compare it to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_wrist_force_successful = ...\n",
    "max_wrist_force_successful = ...\n",
    "\n",
    "min_wrist_force_unsuccessful = ...\n",
    "max_wrist_force_unsuccessful = ...\n",
    "\n",
    "print(f\"Successful: Minimum {min_wrist_force_successful} and maximum {max_wrist_force_successful} value of wrist force-torque chanel\")\n",
    "print(f\"Unsuccessful: Minimum {min_wrist_force_unsuccessful} and maximum {max_wrist_force_unsuccessful} value of wrist force-torque chanel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"boolean_slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Optional: print out all of the indices where the maximum value for the successful pick was reached\n",
    "\n",
    "np.where is the method you want; it returns a tuple (think list) with two lists, one for each dimension. To get out the pairs of indices, you want the first element of the first list and the first element of the second list, and so on. You can do this with a for loop, using zip to zip together the two arrays.\n",
    "\n",
    "- for r, c in zip( ):\n",
    "\n",
    "Some gotchas: it's easiest to do where on the entire pick_data set, but then you'll get indices that are NOT the\n",
    "ones you want (other data channels). If you do max on the sliced matrix, then you'll get indices on the sliced\n",
    "matrix, not the original... So either you need to filter out indices that are not the channel you want with an\n",
    "**if** statement (the modulo operator **%** is useful here) OR adjust the column index by doing offset + index * n_total_dims.\n",
    "\n",
    "See the slides for help on converting to and fro from row column indexing, and see the Miro diagram for more info on re-configuring the output of **where**.\n",
    "\n",
    "This is OPTIONAL for the lab, but we will be coming back to this in the homework. Extra credit grades are adjusted in Canvas, btw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use where to get out the indices. You can use == OR np.isclose() here; either works, but np.isclose will give \n",
    "#. you slightly more results\n",
    "\n",
    "all_indices_from_where = ...\n",
    "# for all row, column in all_indices_from_where\n",
    "#.   if this is the column for wrist force \n",
    "#.      print(f\"Row: {r}, Time step: {c // n_time_steps} Successful y/n: {pick_data[r, -1] == 1}, value: {pick_data[r, c]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit just the .ipynb file to Gradescope. Don't change the provided variable names or autograding will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "otter": {
   "tests": {
    "boolean_slicing": {
     "name": "boolean_slicing",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(min_wrist_force_successful, -193.3288574)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(max_wrist_force_successful, 429.9679871)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(min_wrist_force_unsuccessful, -172.1878052)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(max_wrist_force_unsuccessful, 429.9679871)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "calc_stats_in_function": {
     "name": "calc_stats_in_function",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def compare_files():\n...     with open(\"data/week1_student_results.json\", \"r\") as fp:\n...         student = json.load(fp)\n...     with open(\"data/week1_check_results.json\", \"r\") as fp:\n...         check = json.load(fp)\n>>> \n...     for k, v in check.items():\n...         try:\n...             if k == \"Data channels\":\n...                 # The data channels list\n...                 for i, d in enumerate(student[k]):\n...                     if not d == v[i]:\n...                         print(f\"miss-match {d} {v[i]}\")\n...                         return False\n...             else:\n...                 if not v == student[k]:\n...                     print(f\"Miss-match key-item {k} {v} {student[k]}\")\n...                     return False\n...         except KeyError:\n...             print(f\"Missing key {k}\")\n...             return False\n...     return True\n>>> \n>>> compare_files()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "channel_index": {
     "name": "channel_index",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> row_max_wrist_torque_z == (82, 863)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "initialize_data": {
     "name": "initialize_data",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> pick_data_description[\"n_total_dims\"] == 33\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> pick_data_description[\"n_time_steps\"] == 40\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "slicing": {
     "name": "slicing",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(min_wrist_force, -193.3288574)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(max_wrist_force, 429.9679871)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
