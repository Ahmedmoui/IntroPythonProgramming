{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Lab_1_data_numpy.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Statistical analysis of data using numpy\n",
    "\n",
    "Resources: What you're doing laid out visually, see miro https://miro.com/app/board/uXjVOWs8R4Y=/?share_link_id=567398312390 Lab 1: frame, mapping between task and code and the Lab slides https://docs.google.com/presentation/d/1lVYGqoStt0ZdnRAYMfF9Km6f0NgMNkuYgINsRhXASwI/edit?usp=sharing\n",
    "\n",
    "Motivation: Whether you're in engineering or business or health care - almost any field nowadays - you need to be able to work with data. Just about every thing that touches a computer now has the ability to store data. Most of this data will be numbers, but sometimes it will be qualitative data (think 3 people like this, 10 people don't).\n",
    "\n",
    "You can do a lot of data analysis with spreadsheets, but at some point it's almost always easier to write some code to either *put* data into a spread sheet in a form that's useful, to *pull* specific data from one (or more) spreadsheets, or to automate some processes (like creating six custom plots from this month's data showing price trends). Being able to write a bit of code to clean up or re-purpose data is really useful, and not too difficult.\n",
    "\n",
    "- Lab week 1: Read in data, re-arrange it, and use it to do (text-based) statistical analysis\n",
    "- Lab week 2: Plot the data you worked with in lab week 1\n",
    "- Homework weeks 1 & 2: \n",
    "-- Make the code more general, so you can look at different data channels\n",
    "-- Make nicer plots\n",
    "\n",
    "Some notes on the data you'll be working with. This is real data captured by a robotic hand designed to pick fruit. The hand is instrumented with a couple sensors (IMUs in each of the three fingers, force and torque information at the wrist and information from the motors driving the three fingers). \n",
    "\n",
    "Big picture: We want to know if we can detect if the apple was picked or not from the sensor data. Each row of the Data/proxy_pick_data.csv file is data from a single picking trial. Each group of n columns represents onetime step. We want to plot/analyze data from different data channels to see if there is a difference between the successful and unsuccessful picks.\n",
    "\n",
    "For this lab the goal is to pull out one data channel (the wrist torque sensor, z value) and print out statistics for failed versus successful picks. Yes, you could do all of this by manually going into the spreadsheet, sorting\n",
    "columns, and setting up some spreadsheet formulas. That works for one data channel... but what if you want to do a different one? Or the data file format changes because someone added another sensor? Or you're asked to throw out the biggest n samples?\n",
    "\n",
    "Yes, this is going to be frustrating/seem like a lot of work for nothing the first time you do it. The point is not\n",
    "to do this particularly task, but to learn how to access data in dictionaries, lists, and numpy arrays to \"pull out\"\n",
    "data that you're interested in. Yes, I could just tell you to use numpy slicing to pull out every 15th column,\n",
    "starting with the 3rd column, and sort by the last column, but where would the fun be in that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that we need to import - numpy and json (for loading the description file)\n",
    "import numpy as np\n",
    "import json as json\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data\n",
    "First step, read in the data from Data/proxy_pick_data.csv and put it in a numpy array pick_data. Don't forget to set the delimiter.\n",
    " - see numpy loadtxt and a_tutorial_numpy.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pick_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of picks: {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"count_rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON, lists, and dictionaries: Getting information from a file\n",
    "The format of the spreadsheet data is given in Data/data_format.json. Open up the file using any text editor and look through it to see if it makes sense. Also open up proxy_pick_data.csv in a spread sheet editor and make sure you understand the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reads in the json data\n",
    "try:\n",
    "    with open(\"data/proxy_data_description.json\", \"r\") as fp:\n",
    "        pick_data_description = json.load(fp)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file was not found; check that the data directory is in the current one and the file is in that directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many sensor data channels, how many time steps?\n",
    "Figure out how many data channels there are, total, for one time step.\n",
    "\n",
    "### Step 1: Figure out how to get the \"Data channels\" list out of pick_data_description\n",
    "Note: pick_data_description is a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_channels = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_total_dims = 0\n",
    "#. for each item in data channels\n",
    "#.    Get the number of dimmensions in that element and add it to n_total_dims\n",
    "#.  Note that each item in data channels is a dictionary\n",
    "print(f\"Number of data channels items in list: {}, total summed number of dimensions: {n_total_dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of time steps\n",
    "Now do a bit of math to figure out the total number of time steps (number of columns / number of dimensions)\n",
    "\n",
    "Make sure this is an integer\n",
    "\n",
    "And remember that there is one extra column (the last one) that stores if the pick was successful or not\n",
    "\n",
    "Extra help: Google python 3 integer divide for a bit more information on how to get an integer back out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_time_steps = ...\n",
    "print(f\"Number of time steps: {n_time_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"read_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data slicing to get out the Wrist torque data\n",
    "\n",
    "Practice slicing - pull out the Z value of the Wrist torque for all picks\n",
    "\n",
    "You are free to use the fact that the name of the data channel you want is Wrist torque, but you should get\n",
    "the actual index value from the dictionary, not just do index = 7 (suppose someone changed the order of the data...).\n",
    "\n",
    "There are several ways to do this; the simplest is to loop through all of the data channels looking for the one\n",
    "that is called \"Wrist torque\" and then set the index offset value from that. It would be a good idea to check that you actually found the right starting index by looking at the .json file. Don't forget that numpy indexes from 0\n",
    "\n",
    "Note: Use ==, not **is**, for the string comparison. \n",
    "\n",
    "The z channel is the 3rd one (the starting index field in the json file gives the x channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_name = \"Wrist torque\"\n",
    "index_wrist_torque_offset = -1  #  Set it to a value that is NOT a valid index\n",
    "\n",
    "# for each channel in data channels\n",
    "#     if this channel's name is the one I'm looking for    \n",
    "#.        Set index_wrist_torque_offset (don't forget the z offset)\n",
    "\n",
    "\n",
    "# Check that you actually set the value somewhere in the loop - this is \"defensive coding\"\n",
    "if index_wrist_torque_offset is -1:\n",
    "    print(f\"Error: No channel {channel} found\")\n",
    "    \n",
    "print(f\"Offset for wrist torque: {index_wrist_torque_offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"channel_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use slicing to get out all of the wrist torque data and calculate the min and the max\n",
    "\n",
    "This is a pretty complicated slice. Steps to get there:\n",
    "-First, use the slice operator, selecting all rows and columns, **data[:, :]** to calculate the minimum across the entire matrix of data. This should be the same as **np.min(pick_data)**\n",
    "- Now change the column slice from all columns to starting at the offset value.\n",
    "- Now change the slice to take a step/stride of **n_total_dims** instead of 1\n",
    "- Reminder: slicing is  **start:end:step**\n",
    "\n",
    "Note: You don't need to put an end value in - just leave it blank\n",
    "\n",
    "Remember: The data is in **pick_data**, not **pick_data_description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "min_wrist_torque = ...\n",
    "max_wrist_torque = ...\n",
    "print(f\"Minimum {min_wrist_torque} and maximum {max_wrist_torque} value of wrist torque z channel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean slicing to get successful versus unsuccessful picks out\n",
    "\n",
    "Now for the fun one - do the same but ONLY for successful (last column is 1) picks versus unsuccessful (last column is 0)\n",
    "\n",
    "Note: Use == 1, not **is** 1\n",
    "\n",
    "It may be helpful here to explicitly create a boolean array that is # rows X 1 to use as the row index for the\n",
    "pick_data, rather than trying to do it \"in-place\". Then you can check that the array is correct (print it out - it should have Trues and Falses in the same order as the 1s and 0s in the spreadsheet's last column).\n",
    "\n",
    "This boolean array replaces the **:** row index: **data[boolean_array, start:end:step]**\n",
    "\n",
    "The boolean array is created by doing a comparison, for example, **data == 1**. In this case, you want to get out all rows, but only the LAST column of the data, and compare it to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_wrist_torque_successful = ...\n",
    "max_wrist_torque_successful = ...\n",
    "\n",
    "min_wrist_torque_unsuccessful = ...\n",
    "max_wrist_torque_unsuccessful = ...\n",
    "\n",
    "print(f\"Successful: Minimum {min_wrist_torque_successful} and maximum {max_wrist_torque_successful} value of wrist torque z channel\")\n",
    "print(f\"Unsuccessful: Minimum {min_wrist_torque_unsuccessful} and maximum {max_wrist_torque_unsuccessful} value of wrist torque z channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"boolean_slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Optional: print out all of the indices where the maximum value for the successful pick was reached\n",
    "\n",
    "np.where is the method you want; it returns a tuple (think list) with two lists, one for each dimension. To get out the pairs of indices, you want the first element of the first list and the first element of the second list, and so on. You can do this with a for loop, using zip to zip together the two arrays.\n",
    "\n",
    "- for r, c in zip( ):\n",
    "\n",
    "Some gotchas: it's easiest to do where on the entire pick_data set, but then you'll get indices that are NOT the\n",
    "ones you want (other data channels). If you do max on the sliced matrix, then you'll get indices on the sliced\n",
    "matrix, not the original... So either you need to filter out indices that are not the channel you want with an\n",
    "**if** statement (the modulo operator **%** is useful here) OR adjust the column index by doing offset + index * n_total_dims.\n",
    "\n",
    "See the slides for help on converting to and fro from row column indexing, and see the Miro diagram for more info on re-configuring the output of **where**.\n",
    "\n",
    "This is OPTIONAL for the lab, but we will be coming back to this in the homework. Extra credit grades are adjusted in Canvas, btw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use where to get out the indices. You can use == OR np.isclose() here; either works, but np.isclose will give \n",
    "#. you slightly more results\n",
    "\n",
    "all_indices_from_where = ...\n",
    "# for all row, column in all_indices_from_where\n",
    "#.   if this is the column for wrist torque \n",
    "#.      print(f\"Row: {r}, Time step: {c // n_time_steps} Successful y/n: {pick_data[r, -1] == 1}, value: {pick_data[r, c]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit just the .ipynb file to Gradescope. Don't change the provided variable names or autograding will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "otter": {
   "tests": {
    "boolean_slicing": {
     "name": "boolean_slicing",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(min_wrist_torque_successful, -0.293665094)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(max_wrist_torque_successful, 0.340460618)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(min_wrist_torque_unsuccessful, -0.62552044)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(max_wrist_torque_unsuccessful, 0.326538637)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "channel_index": {
     "name": "channel_index",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> index_wrist_torque_offset == 5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "count_rows": {
     "name": "count_rows",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> pick_data.shape[0] == 660\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "read_json": {
     "name": "read_json",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> n_total_dims == 33\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> n_time_steps == 40\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "slicing": {
     "name": "slicing",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(min_wrist_torque, -0.62552044)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(max_wrist_torque, 0.340460618)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
