{
"cells": [
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"# Initialize Otter\n",
"import otter\n",
"grader = otter.Notebook(\"Lab_1_data_numpy.ipynb\")"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"# Lab 1: Statistical analysis of data using numpy\n",
"\n",
"Resources: What you're doing laid out visually, see miro https://miro.com/app/board/uXjVOWs8R4Y=/?share_link_id=567398312390 Lab 1: frame, mapping between task and code and the Lab slides https://docs.google.com/presentation/d/1lVYGqoStt0ZdnRAYMfF9Km6f0NgMNkuYgINsRhXASwI/edit?usp=sharing\n",
"\n",
"Motivation: Whether you're in engineering or business or health care - almost any field nowadays - you need to be able to work with data. Just about every thing that touches a computer now has the ability to store data. Most of this data will be numbers, but sometimes it will be qualitative data (think 3 people like this, 10 people don't).\n",
"\n",
"You can do a lot of data analysis with spreadsheets, but at some point it's almost always easier to write some code to either *put* data into a spread sheet in a form that's useful, to *pull* specific data from one (or more) spreadsheets, or to automate some processes (like creating six custom plots from this month's data showing price trends). Being able to write a bit of code to clean up or re-purpose data is really useful, and not too difficult.\n",
"\n",
"- Lab week 1: Read in data, re-arrange it, and use it to do (text-based) statistical analysis\n",
"- Lab week 2: Plot the data you worked with in lab week 1\n",
"- Homework weeks 1 & 2: \n",
"-- Make the code more general, so you can look at different data channels\n",
"-- Make nicer plots\n",
"\n",
"Some notes on the data you'll be working with. This is real data captured by a robotic hand designed to pick fruit. The hand is instrumented with a couple sensors (IMUs in each of the three fingers, force and torque information at the wrist and information from the motors driving the three fingers). Each of these sensors outputs a data stream, which we've stored in a csv file. \n",
"\n",
"Big picture: We want to know if we can detect if the apple was picked or not from the sensor data. Each row of the Data/proxy_pick_data.csv file is data from a single picking trial. Each group of n columns represents one time step. We want to plot/analyze data from different data channels to see if there is a difference between the successful and unsuccessful picks.\n",
"\n",
"For this lab the goal is to pull out one data channel (the wrist torque sensor, z value) and print out statistics for failed versus successful picks. Yes, you could do all of this by manually going into the spreadsheet, sorting\n",
"columns, and setting up some spreadsheet formulas. That works for one data channel... but what if you want to do a different one? Or the data file format changes because someone added another sensor? Or you're asked to throw out the biggest n samples?\n",
"\n",
"Yes, this is going to be frustrating/seem like a lot of work for nothing the first time you do it. The point is not\n",
"to do this particularly task, but to learn how to access data in dictionaries, lists, and numpy arrays to \"pull out\"\n",
"data that you're interested in. Yes, I could just tell you to use numpy slicing to pull out every 15th column,\n",
"starting with the 3rd column, and sort by the last column, but where would the fun be in that?"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Libraries that we need to import - numpy and json (for loading the description file)\n",
"import numpy as np\n",
"import json as json"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Reading in data\n",
"TODO First step, read in the data from Data/proxy_pick_data.csv and put it in a numpy array pick_data. Don't forget to set the delimiter.\n",
" - see numpy loadtxt and a_tutorial_numpy.py\n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"pick_data = ..."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# TODO - set the n_picks variable, then print it out. Do NOT just put in a number - use the variable pick_data to calculate this\n",
"n_picks = ...\n",
"print(f\"Number of picks: {}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# TODO - set the variable n_successful and print it out. Do NOT just put in a number - use the variable pick_data\n",
"#   Calculating the number of successful picks: The number of values in the last column that are 1 (use np.sum)\n",
"\n",
"print(f\"Number of successful picks: {}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"count_rows\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## JSON, lists, and dictionaries: Getting information from a file\n",
"The format of the spreadsheet data is given in Data/data_format.json. TODO: Open up the file using any text editor and look through it to see if it makes sense. Also open up proxy_pick_data.csv in a spread sheet editor and make sure you understand the data format."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"# This reads in the json data\n",
"try:\n",
"    with open(\"Data/proxy_data_description.json\", \"r\") as fp:\n",
"        pick_data_description = json.load(fp)\n",
"except FileNotFoundError:\n",
"    print(f\"The file was not found; check that the data directory is in the current one and the file is in that directory\")\n"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## How many sensor data channels, how many time steps?\n",
"TODO: Figure out how many data channels there are, total, for one time step.\n",
"\n",
"### Step 1: Figure out how to get the \"Data channels\" list out of pick_data_description\n",
"Note: pick_data_description is a dictionary."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# TODO - use the key \"Data channels\" to get out the list of data channels from pick_data_description\n",
"data_channels = ..."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"n_total_dims = 0\n",
"# TODO 1: turn this pseudo code into real code. \n",
"#. for each item in data channels\n",
"#.    Get the number of dimmensions in that element and add it to n_total_dims\n",
"#.  Note that each item in data channels is a dictionary\n",
"# TODO: Fill in the number of data channels - again, use a variable, not just a number\n",
"print(f\"Number of data channels items in list: {}, total summed number of dimensions: {n_total_dims}\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"### Number of time steps\n",
"Now do a bit of math to figure out the total number of time steps (number of columns / number of dimensions)\n",
"\n",
"Make sure this is an integer\n",
"\n",
"And remember that there is one extra column (the last one) that stores if the pick was successful or not\n",
"\n",
"Extra help: Google python 3 integer divide for a bit more information on how to get an integer back out"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# TODO: Calculate number of time steps\n",
"n_time_steps = ...\n",
"print(f\"Number of time steps: {n_time_steps}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"read_json\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"##### Data slicing to get out the Wrist torque data\n",
"\n",
"Practice slicing - pull out the Z value of the Wrist torque for all picks\n",
"\n",
"You are free to use the fact that the name of the data channel you want is Wrist torque, and that z is the 3rd one, but you should get the actual offset index value from the dictionary, not just do index_wrist_torque_offset = 5 (suppose someone changed the order of the data...).\n",
"\n",
"There are several ways to do this; the simplest is to loop through all of the data channels looking for the one\n",
"that is called \"Wrist torque\" and then set the index offset value from that. It would be a good idea to check that you actually found the right starting index by looking at the .json file. Don't forget that numpy indexes from 0.\n",
"\n",
"Note: Use ==, not **is**, for the string comparison. \n",
"\n",
"The **z** channel is the 3rd one (the starting index field in the json file gives the index for the x channel)."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"channel_name = \"Wrist torque\"\n",
"index_wrist_torque_offset = -1  #  Set it to a value that is NOT a valid index\n",
"# TODO: Turn this pseudo code into real code\n",
"# for each channel in data channels\n",
"#     if this channel's name is the one I'm looking for    \n",
"#.        Set index_wrist_torque_offset (don't forget the z offset)\n",
"\n",
"\n",
"# Check that you actually set the value somewhere in the loop - this is \"defensive coding\"\n",
"if index_wrist_torque_offset == -1:\n",
"    print(f\"Error: No channel {channel} found\")\n",
"    \n",
"print(f\"Offset for wrist torque: {index_wrist_torque_offset}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"channel_index\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Compute stats: Now use slicing to get out all of the wrist torque data and calculate the min and the max\n",
"\n",
"This is a pretty complicated slice. Steps to get there:\n",
"\n",
"- First, use the slice operator, selecting all rows and columns, **data[:, :]** to calculate the minimum across the entire matrix of data. This should be the same as **np.min(pick_data)**\n",
"- Now change the column slice from all columns to starting at the offset value.\n",
"- Now change the slice to take a step/stride of **n_total_dims** instead of 1\n",
"- Reminder: slicing is  **start:end:step**\n",
"\n",
"Note: You don't need to put an end value in - just leave it blank if you want to go all the way to the end\n",
"\n",
"Remember: The data is in **pick_data**, not **pick_data_description**\n",
"\n",
"Do NOT use a **for** loop for this - use slicing."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"# TODO: Use slicing to get the columns of data you want, and then use min and max to get the min and max values\n",
"min_wrist_torque = ...\n",
"max_wrist_torque = ...\n",
"print(f\"Minimum {min_wrist_torque} and maximum {max_wrist_torque} value of wrist torque z channel\")\n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"slicing\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Boolean slicing to get successful versus unsuccessful picks out\n",
"\n",
"Now for the fun one - do the same slicing but ONLY for successful picks versus unsuccessful. This data is stored in the last column - if the last column is 1 the pick was successful (it is 0 if not)\n",
"\n",
"Note: Use **== 1**, not **is 1**\n",
"\n",
"It may be helpful here to explicitly create a boolean array that is **(number of rows) X 1** to use as the row index for the pick_data, rather than trying to do it \"in-place\". Then you can check that the array is correct (print it out - it should have Trues and Falses in the same order as the 1s and 0s in the spreadsheet's last column).\n",
"\n",
"This boolean array replaces the **:** row index: **data[boolean_array, start:end:step]**\n",
"\n",
"The boolean array is created by doing a comparison, for example, **data == 1**. In this case, you want to get out all rows, but only the LAST column of the data, and compare it to 1."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# TODO: Create a boolean array to pick out the successful columns, and use that to pick out the rows. Then\n",
"#. calculate min and max\n",
"min_wrist_torque_successful = ...\n",
"max_wrist_torque_successful = ...\n",
"\n",
"# TODO: Same thing, but this time pick out the unsuccessful columns\n",
"min_wrist_torque_unsuccessful = ...\n",
"max_wrist_torque_unsuccessful = ...\n",
"\n",
"print(f\"Successful: Minimum {min_wrist_torque_successful} and maximum {max_wrist_torque_successful} value of wrist torque z channel\")\n",
"print(f\"Unsuccessful: Minimum {min_wrist_torque_unsuccessful} and maximum {max_wrist_torque_unsuccessful} value of wrist torque z channel\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"boolean_slicing\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"<!-- BEGIN QUESTION -->\n",
"\n",
"## Optional: print out all of the indices where the maximum value for the successful pick was reached\n",
"\n",
"**np.where** is the method you want; it returns a tuple (think list) with two lists, one for each dimension. To get out the pairs of indices, you want the first element of the first list and the first element of the second list, and so on. You can do this with a for loop, using **zip** to zip together the two arrays.\n",
"\n",
"- for r, c in zip( ):\n",
"\n",
"Some gotchas: it's easiest to do where on the entire pick_data set, but then you'll get indices that are NOT the\n",
"ones you want (other data channels). If you do max on the sliced matrix, then you'll get indices on the sliced\n",
"matrix, not the original... So either you need to filter out indices that are not the channel you want with an\n",
"**if** statement (the modulo operator **%** is useful here) OR adjust the column index by doing **offset + index * n_total_dims**.\n",
"\n",
"See the slides for help on converting to and fro from row column indexing, and see the Miro diagram for more info on re-configuring the output of **where**.\n",
"\n",
"This is OPTIONAL for the lab, but we will be coming back to this in the homework. "
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"# Use where to get out the indices. You can use == OR np.isclose() here; either works. In general, use .isclose for \n",
"#. floating point comparisons.\n",
"# Append the row number of any matches to the max into this list\n",
"all_rows_with_max = []\n",
"\n",
"\n",
"all_indices_from_where = ...\n",
"# for all row, column in all_indices_from_where\n",
"#.   if this is the column for wrist torque \n",
"#.      print(f\"Row: {r}, Time step: {c // n_time_steps} Successful y/n: {pick_data[r, -1] == 1}, value: {pick_data[r, c]}\")\n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"optional_where\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"<!-- END QUESTION -->\n",
"\n",
"## Hours and collaborators\n",
"Required for every assignment - fill out before you hand-in.\n",
"\n",
"Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
"\n",
"Listing hours helps us track if the assignments are too long."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"tags": []
},
"outputs": [],
"source": [
"\n",
"# List of names (creates a set)\n",
"worked_with_names = {\"not filled out\"}\n",
"# List of URLS (creates a set)\n",
"websites = {\"not filled out\"}\n",
"# Approximate number of hours, including lab/in-class time\n",
"hours = -1.5\n",
"\n",
"# for all row, column in all_indices_from_where\n",
"#.   if this is the column for wrist torque \n",
"#.      print(f\"Row: {r}, Time step: {c // n_time_steps} Successful y/n: {pick_data[r, -1] == 1}, value: {pick_data[r, c]}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"grader.check(\"hours_collaborators\")"
]
},
{
"cell_type": "markdown",
"metadata": {
"deletable": false,
"editable": false
},
"source": [
"## Submission\n",
"\n",
"Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
"\n",
"Submit just the .ipynb file to Gradescope (Lab 1 Arrays). You do not need to submit the data files. Don't change the provided variable names or autograding will fail. Look at the Gradescope grading rubric for code-quality checks."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {
"deletable": false,
"editable": false
},
"outputs": [],
"source": [
"# Save your notebook first, then run this cell to export your submission.\n",
"grader.export(run_tests=True)"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
" "
]
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.7.4"
},
"otter": {
"OK_FORMAT": true,
"tests": {
"boolean_slicing": {
"name": "boolean_slicing",
"points": 2,
"suites": [
{
"cases": [
{
"code": ">>> assert np.isclose(min_wrist_torque_successful, -0.293665094)\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert np.isclose(max_wrist_torque_successful, 0.340460618)\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert np.isclose(min_wrist_torque_unsuccessful, -0.62552044)\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert np.isclose(max_wrist_torque_unsuccessful, 0.326538637)\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"channel_index": {
"name": "channel_index",
"points": 2,
"suites": [
{
"cases": [
{
"code": ">>> assert index_wrist_torque_offset == 5\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"count_rows": {
"name": "count_rows",
"points": 1,
"suites": [
{
"cases": [
{
"code": ">>> assert pick_data.shape[0] == 660\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert n_picks == 660\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert n_successful == 355\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"hours_collaborators": {
"name": "hours_collaborators",
"points": 1,
"suites": [
{
"cases": [
{
"code": ">>> assert not 'not filled out' in worked_with_names\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert not 'not filled out' in websites\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert hours > 0\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"optional_where": {
"name": "optional_where",
"points": 0,
"suites": [
{
"cases": [
{
"code": ">>> assert all_rows_with_max[0] == 82\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"read_json": {
"name": "read_json",
"points": 2,
"suites": [
{
"cases": [
{
"code": ">>> assert n_total_dims == 33\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert n_time_steps == 40\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
},
"slicing": {
"name": "slicing",
"points": 2,
"suites": [
{
"cases": [
{
"code": ">>> assert np.isclose(min_wrist_torque, -0.62552044)\n",
"hidden": false,
"locked": false
},
{
"code": ">>> assert np.isclose(max_wrist_torque, 0.340460618)\n",
"hidden": false,
"locked": false
}
],
"scored": true,
"setup": "",
"teardown": "",
"type": "doctest"
}
]
}
}
}
},
"nbformat": 4,
"nbformat_minor": 2
}
